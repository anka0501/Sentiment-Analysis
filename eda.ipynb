{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\annag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import re\n",
    "import string \n",
    "import contractions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk \n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "stop_words = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       entity sentiment  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                               tweet  \n",
       "0  I am coming to the borders and I will kill you...  \n",
       "1  im getting on borderlands and i will kill you ...  \n",
       "2  im coming on borderlands and i will murder you...  \n",
       "3  im getting on borderlands 2 and i will murder ...  \n",
       "4  im getting into borderlands and i can murder y...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
    "\n",
    "train = pd.read_csv(path + '\\\\twitter_training.csv')\n",
    "val = pd.read_csv(path + '\\\\twitter_validation.csv')\n",
    "\n",
    "train.columns = ['id', 'entity', 'sentiment', 'tweet']\n",
    "val.columns = ['id', 'entity', 'sentiment', 'tweet']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "entity         0\n",
       "sentiment      0\n",
       "tweet        686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of nulls in each column\n",
    "train[['id', 'entity', 'sentiment', 'tweet']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "entity       0\n",
       "sentiment    0\n",
       "tweet        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val[['id', 'entity', 'sentiment', 'tweet']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(df, name):\n",
    "    \"\"\"Print distribution plot of sentiment\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = ['red', 'green', 'blue', 'orange']\n",
    "    df['sentiment'].value_counts().plot(kind='bar', color=colors)\n",
    "\n",
    "    # sns.countplot(x='Sentiment', data=df, palette='viridis', order=sentiment_counts.index)\n",
    "    plt.title(f'Distribution of sentiment ({name} set)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_plot(train, 'train')\n",
    "draw_plot(val, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean input text by lowercasing and removing punctuation.\n",
    "    \"\"\"\n",
    "    # lower case\n",
    "    text = text.lower() \n",
    "    # remove links\n",
    "    text = re.compile(r\"https?://\\S+|www\\.\\S+\").sub(\"\", text)\n",
    "    # remove punctuations\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    text = text.translate(table)\n",
    "    # remove unique char\n",
    "    text = re.sub(r'(?:^| )\\w(?:$| )', ' ',text).strip()\n",
    "    # contractions\n",
    "    text = \" \".join([contractions.fix(word) for word in text.split()])\n",
    "\n",
    "    replacements = {\n",
    "        r\"'s\\b\": \"\",\n",
    "        r\"\\s+\": \" \",\n",
    "    }\n",
    "\n",
    "    for replace, by in replacements.items():\n",
    "        text = re.sub(replace, by, text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_clean'] = train['tweet'].apply(lambda x: clean_text(x))\n",
    "val['tweet_clean'] = val['tweet'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Tokenize text and remove stopwords.\n",
    "    \"\"\"\n",
    "    text = text.apply(word_tokenize)\n",
    "    text = text.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet_no_stopwords'] = remove_stopwords(train['tweet_clean'])\n",
    "train['tweet_no_stopwords'] = train['tweet_no_stopwords'].apply(lambda x: ' '.join(eval(str(x))))\n",
    "val['tweet_no_stopwords'] = remove_stopwords(val['tweet_clean'])\n",
    "val['tweet_no_stopwords'] = val['tweet_no_stopwords'].apply(lambda x: ' '.join(eval(str(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['tweet_no_stopwords']\n",
    "#X_train = train.iloc[:, 3].fillna('').astype(str).values\n",
    "y_train = train['sentiment']\n",
    "#y_train = train.iloc[:, 2].values \n",
    "\n",
    "X_val = val['tweet_no_stopwords']\n",
    "#X_val = val.iloc[:, 3].fillna('').astype(str).values\n",
    "y_val = val['sentiment']\n",
    "#y_val = val.iloc[:, 2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataStructure:\n",
    "    def __init__(self,X,typedt,y_train=y_train,y_val=y_val,X_train=X_train,shuffle=True):\n",
    "        self.X = X\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.typedt = typedt\n",
    "        self.X_train = X_train\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def encode_data(self):\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train = label_encoder.fit_transform(self.y_train)\n",
    "        y_val = label_encoder.transform(self.y_val)\n",
    "        if self.typedt == \"train\":\n",
    "            return y_train\n",
    "        else:\n",
    "            return y_val\n",
    "    \n",
    "    def get_tokenizer(self):\n",
    "        tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "        tokenizer.fit_on_texts(self.X_train)\n",
    "        return tokenizer\n",
    "    \n",
    "    def tokenize_data(self):\n",
    "        X_seq = self.get_tokenizer().texts_to_sequences(self.X)\n",
    "        X_pad = pad_sequences(X_seq, maxlen=50, padding='post')\n",
    "        return X_pad\n",
    "    \n",
    "    def tensor_data(self):\n",
    "        dataset = TensorDataset(torch.tensor(self.tokenize_data(), dtype=torch.long), torch.tensor(self.encode_data(), dtype=torch.long))\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=self.shuffle)\n",
    "        return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = DataStructure(X_train,'train',shuffle=True)\n",
    "dataloader_train = structure.tensor_data()\n",
    "structure_val = DataStructure(X_val,'val',shuffle=False)\n",
    "dataloader_val = structure_val.tensor_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeatureExtractor(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.gru = nn.GRU(8, 64, num_layers=2, batch_first=True)\n",
    "#         self.fc = nn.Sequential(nn.ReLU(True),\n",
    "#                                 nn.Linear(64, 64), \n",
    "#                                 nn.ReLU(True))\n",
    "#     def forward(self, x):\n",
    "#         out, _ = self.gru(x)\n",
    "#         out = self.fc(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, vocab_size, embedding_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers = 1, bidirectional = False, bias = True, batch_first=True)  \n",
    "        self.layers = nn.Sequential(\n",
    "                        nn.GELU(),\n",
    "                        nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out, _ = self.gru(embedded) # return tuple not tensor\n",
    "        out = self.layers(out[:, -1, :])\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RobertaClass(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(RobertaClass, self).__init__()\n",
    "#         self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "#         self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "#         self.dropout = torch.nn.Dropout(0.3)\n",
    "#         self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "#         output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "#         hidden_state = output_1[0]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         pooler = self.pre_classifier(pooler)\n",
    "#         pooler = torch.nn.ReLU()(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "#         output = self.classifier(pooler)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definindo o modelo GRU\n",
    "# class GRUClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, vocab_size, embedding_dim):\n",
    "#         super(GRUClassifier, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.gru_forward = nn.GRU(embedding_dim, hidden_dim, num_layers = 1, bidirectional = False, bias = True, batch_first=True)\n",
    "#         self.gru_backward = nn.GRU(hidden_dim, hidden_dim, num_layers = 1, bidirectional = False, bias = True, batch_first=True)\n",
    "#         # self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "#         self.gelu = nn.GELU()\n",
    "#         # self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x)\n",
    "#         x, _ = self.gru_forward(embedded)\n",
    "#         x = self.gelu(x[:, -1, :])\n",
    "#         x = torch.flip(x, dims=[1])\n",
    "#         x, _ = self.gru_backward(x)\n",
    "#         x = torch.flip(x, dims=[1])\n",
    "#         out = self.gelu(x)\n",
    "#         #out = out[:, -1, :]  # Pegando a ltima sada da GRU\n",
    "#         #out = self.fc(out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BGRUModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_classes, vocab_size, embedding_dim):\n",
    "#         super(BGRUModel, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.bgru = nn.GRU(embedding_dim, hidden_size, num_layers, bidirectional=True)\n",
    "#         self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out, _ = self.bgru(x)\n",
    "#         out = self.fc(out[:, -1, :])  \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRUClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, output_dim, vocab_size, embedding_dim):\n",
    "#         super(GRUClassifier, self).__init__()\n",
    "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded = self.embedding(x)\n",
    "#         gru_out, _ = self.gru(embedded)\n",
    "#         gru_out = gru_out[:, -1, :]  # Pegando a ltima sada da GRU\n",
    "#         out = self.fc(gru_out)\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "output_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUModel(\n",
       "  (embedding): Embedding(10000, 64)\n",
       "  (gru): GRU(64, 128, batch_first=True)\n",
       "  (layers): Sequential(\n",
       "    (0): GELU(approximate='none')\n",
       "    (1): Linear(in_features=128, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru = GRUModel(hidden_dim=hidden_dim, output_dim=output_dim, vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "model_gru.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUClassifier(\n",
       "  (embedding): Embedding(10000, 64)\n",
       "  (gru_forward): GRU(64, 128, batch_first=True)\n",
       "  (gru_backward): GRU(128, 128, batch_first=True)\n",
       "  (gelu): GELU(approximate='none')\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = GRUClassifier(input_dim=embedding_dim, hidden_dim=hidden_dim, output_dim=output_dim, vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_callback = train_model(model, dataloader_train, dataloader_val, criterion, optimizer, epochs=20, patience=3, min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calcuate_accuracy(preds, targets):\n",
    "#     n_correct = (preds==targets).sum().item()\n",
    "#     return n_correct\n",
    "\n",
    "# loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "# from pytorch_lightning.metrics.functional import accuracy, f1, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from pytorch_lightning.loggers import TensorBoardLoggerwhich \n",
    "from torchmetrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LightningTransformer(L.LightningModule):\n",
    "#     def __init__(self, vocab_size):\n",
    "#         super().__init__()\n",
    "#         self.model = Transformer(vocab_size=vocab_size)\n",
    "\n",
    "#     def forward(self, inputs, target):\n",
    "#         return self.model(inputs, target)\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         inputs, target = batch\n",
    "#         output = self(inputs, target)\n",
    "#         loss = torch.nn.functional.nll_loss(output, target.view(-1))\n",
    "#         return loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         return torch.optim.SGD(self.model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "  def __init__(self, model): \n",
    "    super(TrainModel,self).__init__()\n",
    "    self.model = model\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, x):\n",
    "        return self.model(x) #inputs\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.forward(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "  \n",
    "#   def test_step(self, batch, batch_idx):\n",
    "#         loss = self(batch).sum()\n",
    "#         self.log(\"test_loss\", loss)\n",
    "  def test_step(self, batch, batch_idx):\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "  \n",
    "#   def predict_step(self, batch):\n",
    "#         inputs, target = batch\n",
    "#         return self.model(inputs, target)\n",
    "  def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        return self(batch)\n",
    "\n",
    "#   def training_epoch_end(self, outputs):\n",
    "#       labels = []\n",
    "#       predictions = []\n",
    "#       for output in outputs:\n",
    "#             for out_labels in output[\"labels\"].detach().cpu():\n",
    "#                   labels.append(out_labels)\n",
    "#             for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "#                   predictions.append(out_predictions)\n",
    "\n",
    "#       labels = torch.stack(labels).int()\n",
    "#       predictions = torch.stack(predictions)\n",
    "\n",
    "#       for i, name in enumerate(LABEL_COLUMNS):\n",
    "#             class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "#             self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_r)\n",
    "                                              \n",
    "\n",
    "  def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | GRUModel         | 715 K \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "715 K     Trainable params\n",
      "0         Non-trainable params\n",
      "715 K     Total params\n",
      "2.860     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 1157/1157 [01:10<00:00, 16.33it/s, loss=0.131, v_num=12, train_loss=0.0688]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 1157/1157 [01:10<00:00, 16.33it/s, loss=0.131, v_num=12, train_loss=0.0688]\n",
      "Testing DataLoader 0: 100%|| 16/16 [00:00<00:00, 52.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">   Runningstage.testing    </span><span style=\"font-weight: bold\">                           </span>\n",
       "<span style=\"font-weight: bold\">          metric           </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.24870845675468445    </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m\u001b[1m                           \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.24870845675468445   \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.24870845675468445}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "np.Inf = np.inf\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor = \"val_loss\", \n",
    "    min_delta = 0.00, \n",
    "    patience = 10, \n",
    "    verbose = False, \n",
    "    mode = \"min\",\n",
    ")\n",
    "\n",
    "# checkpoint_callback = ModelCheckpoint(save_top_k = 1, monitor = \"val_loss\",\n",
    "#                                       dirpath = './best_model', filename='best',\n",
    "#                                       save_last=True\n",
    "#                                       )\n",
    "\n",
    "\n",
    "# checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints\", # where the ckpt will be saved\n",
    "#                                       filename=\"best-checkpoint\", # the name of the best ckpt\n",
    "#                                       save_top_k=1, # save only the best ckpt\n",
    "#                                       verbose=True,\n",
    "#                                       monitor=\"val_loss\", # ckpt will be save according to the validation loss that you need to calculate on the validation step when you train your model\n",
    "#                                       mode=\"min\" # validation loos need to be min\n",
    "#                                       ) \n",
    "\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#                     dirpath=\"checkpoints\", filename=\"best-checkpoint\",\n",
    "#                     save_top_k=1, verbose=True, monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "# checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints\", # where the ckpt will be saved\n",
    "#                                       filename=\"best-checkpoint\", # the name of the best ckpt\n",
    "#                                       save_top_k=1, # save only the best ckpt\n",
    "#                                       verbose=True,\n",
    "#                                       monitor=\"Validation loss\", # ckpt will be save according to the validation loss that you need to calculate on the validation step when you train your model\n",
    "#                                       mode=\"min\" # validation loos need to be min\n",
    "#                                       ) \n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"sentiment\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#         monitor='val_loss',\n",
    "#         dirpath='.\\lightning_logs',\n",
    "#         filename='sample-mnist-epoch{epoch:02d}-val_loss{val/loss:.2f}',\n",
    "#         auto_insert_metric_name=False\n",
    "#  )\n",
    "# filepath=\"./lightning_logs/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.ckpt\"\n",
    "# checkpoint_callback = pl.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, mode='min') #, save_best_only=True\n",
    "\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=10,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    dirpath='./lightning_logs',\n",
    "    filename=\"sample-mnist-{epoch:02d}-{val_loss:.2f}\",\n",
    ")\n",
    "\n",
    "model = TrainModel(model_gru) \n",
    "trainer = pl.Trainer(max_epochs = 1, accelerator = 'cpu',\n",
    "                     logger=logger,\n",
    "                     #callbacks=[early_stop_callback, checkpoint_callback], \n",
    "                     default_root_dir = './lightning_logs',\n",
    "                     callbacks = [early_stop_callback, checkpoint_callback], # [early_stop_callback], #\n",
    "                    val_check_interval = len(dataloader_train)) \n",
    "\n",
    "trainer.fit(model = model, train_dataloaders = dataloader_train)\n",
    "trainer.save_checkpoint(\"./lightning_logs/example.ckpt\")\n",
    "trainer.test(model, dataloaders = dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainModel.__init__() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./lightning_logs/example.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# trainer.predict(dataloaders = dataloader_val)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m new_model\u001b[38;5;241m.\u001b[39mpredict(dataloaders \u001b[38;5;241m=\u001b[39m dataloader_val)\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     65\u001b[0m ):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:205\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningDataModule):\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:250\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cls_spec\u001b[38;5;241m.\u001b[39mvarkw:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     _cls_kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _cls_kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m cls_init_args_name}\n\u001b[1;32m--> 250\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_cls_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# give model a chance to load something\u001b[39;00m\n\u001b[0;32m    253\u001b[0m obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainModel.__init__() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "new_model = model.load_from_checkpoint(checkpoint_path=\"./lightning_logs/example.ckpt\")\n",
    "# trainer.predict(dataloaders = dataloader_val)\n",
    "new_model.predict(dataloaders = dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | GRUModel         | 715 K \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "715 K     Trainable params\n",
      "0         Non-trainable params\n",
      "715 K     Total params\n",
      "2.860     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 1157/1157 [00:42<00:00, 26.98it/s, loss=1.02, v_num=1, train_loss=1.320] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 1157/1157 [00:42<00:00, 26.98it/s, loss=1.02, v_num=1, train_loss=1.320]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# trainer.fit(model_gru, dataloader_train, dataloader_val)\n",
    "# trainer.fit(model = model, train_dataloaders = dataloader_train)\n",
    "\n",
    "# trainer.fit(model, train_dataloaders = dataloader_train, val_dataloaders = dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 16/16 [00:00<00:00, 64.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">   Runningstage.testing    </span><span style=\"font-weight: bold\">                           </span>\n",
       "<span style=\"font-weight: bold\">          metric           </span><span style=\"font-weight: bold\">       DataLoader 0        </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span><span style=\"color: #800080; text-decoration-color: #800080\">    0.9058710932731628     </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m\u001b[1m                           \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m\u001b[35m \u001b[0m\u001b[35m   0.9058710932731628    \u001b[0m\u001b[35m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`.predict(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# automatically auto-loads the best weights from the previous run\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#trainer.test(dataloaders = dataloader_val, ckpt_path = \"best\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, dataloaders \u001b[38;5;241m=\u001b[39m dataloader_val)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataloader_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:949\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;124;03mRun inference on your data.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;124;03mThis will call the model forward function to compute predictions. Useful to perform distributed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;66;03m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# links data to the trainer\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(model, predict_dataloaders\u001b[38;5;241m=\u001b[39mdataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[1;32m--> 990\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__set_ckpt_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_provided\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_provided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_connected\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    992\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicted_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path  \u001b[38;5;66;03m# TODO: remove in v1.8\u001b[39;00m\n\u001b[0;32m    996\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path)\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1413\u001b[0m, in \u001b[0;36mTrainer.__set_ckpt_path\u001b[1;34m(self, ckpt_path, model_provided, model_connected)\u001b[0m\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfast_dev_run:\n\u001b[0;32m   1409\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m   1410\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou cannot execute `.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(ckpt_path=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)` with `fast_dev_run=True`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1411\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please pass an exact checkpoint path to `.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(ckpt_path=...)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         )\n\u001b[1;32m-> 1413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m   1414\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(ckpt_path=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)` is set but `ModelCheckpoint` is not configured to save the best model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;66;03m# load best weights\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_callback, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: `.predict(ckpt_path=\"best\")` is set but `ModelCheckpoint` is not configured to save the best model."
     ]
    }
   ],
   "source": [
    "# automatically auto-loads the best weights from the previous run\n",
    "#trainer.test(dataloaders = dataloader_val, ckpt_path = \"best\")\n",
    "trainer.test(model, dataloaders = dataloader_val)\n",
    "trainer.predict(dataloaders = dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'c:/Users/annag/Desktop/Data Science/Sentiment Analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mTrainModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel_gru\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m trained_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      7\u001b[0m trained_model\u001b[38;5;241m.\u001b[39mfreeze()\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     65\u001b[0m ):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:184\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m     map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m storage, loc: storage\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[1;32m--> 184\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hparams_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     extension \u001b[38;5;241m=\u001b[39m hparams_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\utilities\\cloud_io.py:46\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path_or_url, map_location)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\u001b[38;5;28mstr\u001b[39m(path_or_url), map_location\u001b[38;5;241m=\u001b[39mmap_location)\n\u001b[0;32m     45\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f, map_location\u001b[38;5;241m=\u001b[39mmap_location)\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fsspec\\spec.py:1301\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1301\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1310\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fsspec\\implementations\\local.py:195\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fsspec\\implementations\\local.py:359\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fsspec\\implementations\\local.py:364\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m--> 364\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[0;32m    366\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'c:/Users/annag/Desktop/Data Science/Sentiment Analysis'"
     ]
    }
   ],
   "source": [
    "trained_model = TrainModel.load_from_checkpoint(\n",
    "  trainer.checkpoint_callback.best_model_path,\n",
    "  model_gru\n",
    ")\n",
    "\n",
    "trained_model.eval()\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainModel.predict_step() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# automatically auto-loads the best weights from the previous run\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# predictions = trainer.predict(dataloaders = dataloader_val)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:949\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;124;03mRun inference on your data.\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;124;03mThis will call the model forward function to compute predictions. Useful to perform distributed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m    Returns a list of dictionaries, one for each provided dataloader containing their respective predictions.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;66;03m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:996\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[0;32m    991\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    992\u001b[0m )\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicted_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path  \u001b[38;5;66;03m# TODO: remove in v1.8\u001b[39;00m\n\u001b[1;32m--> 996\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m-> 1166\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1251\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_evaluate()\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_train()\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1311\u001b[0m, in \u001b[0;36mTrainer._run_predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _evaluation_context(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator):\n\u001b[1;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\prediction_loop.py:102\u001b[0m, in \u001b[0;36mPredictionLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28menumerate\u001b[39m(dataloader)\n\u001b[0;32m    100\u001b[0m dl_max_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batches[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_dataloader_idx]\n\u001b[1;32m--> 102\u001b[0m dl_predictions, dl_batch_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_dataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dataloaders\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39mappend(dl_predictions)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_batch_indices\u001b[38;5;241m.\u001b[39mappend(dl_batch_indices)\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\epoch\\prediction_epoch_loop.py:101\u001b[0m, in \u001b[0;36mPredictionEpochLoop.advance\u001b[1;34m(self, dataloader_iter, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[0;32m     97\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_to_device\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, dataloader_idx\u001b[38;5;241m=\u001b[39mdataloader_idx)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\loops\\epoch\\prediction_epoch_loop.py:130\u001b[0m, in \u001b[0;36mPredictionEpochLoop._predict_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch, batch_idx, dataloader_idx)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m--> 130\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1704\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1704\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1707\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\annag\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:388\u001b[0m, in \u001b[0;36mStrategy.predict_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpredict_step_context():\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, PredictStep)\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainModel.predict_step() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "# automatically auto-loads the best weights from the previous run\n",
    "# predictions = trainer.predict(dataloaders = dataloader_val)\n",
    "predictions = trainer.predict(model, dataloaders=dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5, patience=3, min_delta=0.001):\n",
    "    metrics_callback = MetricsCallback()\n",
    "    early_stopping = ValidationLossEarlyStopping(patience=patience, min_delta=min_delta)  \n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            all_train_preds.append(outputs.detach())\n",
    "            all_train_labels.append(labels.detach())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                all_val_preds.append(outputs)\n",
    "                all_val_labels.append(labels)\n",
    "\n",
    "        all_train_preds = torch.cat(all_train_preds)\n",
    "        all_train_labels = torch.cat(all_train_labels)\n",
    "        all_val_preds = torch.cat(all_val_preds)\n",
    "        all_val_labels = torch.cat(all_val_labels)\n",
    "\n",
    "        # Atualizando as mtricas ao final de cada poca\n",
    "        metrics_callback.update_metrics(\n",
    "            epoch,\n",
    "            all_train_labels.cpu().numpy(),\n",
    "            all_train_preds.cpu(),\n",
    "            all_val_labels.cpu().numpy(),\n",
    "            all_val_preds.cpu(),\n",
    "            train_loss / len(train_loader),\n",
    "            val_loss / len(val_loader)\n",
    "        )\n",
    "\n",
    "        # Verificar Early Stopping com base no val_loss\n",
    "        early_stopping(val_loss / len(val_loader))\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Retornando as mtricas ao final do treinamento para plotar\n",
    "    return metrics_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationLossEarlyStopping:\n",
    "    def __init__(self, patience=1, min_delta=0.0):\n",
    "        self.patience = patience  # number of times to allow for no improvement before stopping the execution\n",
    "        self.min_delta = min_delta  # the minimum change to be counted as improvement\n",
    "        self.counter = 0  # count the number of times the validation accuracy not improving\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    # return True when validation loss is not decreased by the `min_delta` for `patience` times \n",
    "    def early_stop_check(self, validation_loss):\n",
    "        if ((validation_loss+self.min_delta) < self.min_validation_loss):\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0  # reset the counter if validation loss decreased at least by min_delta\n",
    "        elif ((validation_loss+self.min_delta) > self.min_validation_loss):\n",
    "            self.counter += 1 # increase the counter if validation loss is not decreased by the min_delta\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "class MetricsCallback:\n",
    "    def __init__(self):\n",
    "        self.train_accuracy = []\n",
    "        self.val_accuracy = []\n",
    "        self.train_f1 = []\n",
    "        self.val_f1 = []\n",
    "        self.train_precision = []\n",
    "        self.val_precision = []\n",
    "        self.train_recall = []\n",
    "        self.val_recall = []\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def update_metrics(self, epoch, y_true_train, y_pred_train, y_true_val, y_pred_val, train_loss, val_loss):\n",
    "        y_pred_train = torch.argmax(y_pred_train, dim=1).cpu().numpy()\n",
    "        y_pred_val = torch.argmax(y_pred_val, dim=1).cpu().numpy()\n",
    "\n",
    "        # Calculando as mtricas para o conjunto de treino\n",
    "        train_acc = (y_true_train == y_pred_train).mean()\n",
    "        train_f1 = f1_score(y_true_train, y_pred_train, average='weighted')\n",
    "        train_precision = precision_score(y_true_train, y_pred_train, average='weighted')\n",
    "        train_recall = recall_score(y_true_train, y_pred_train, average='weighted')\n",
    "\n",
    "        # Calculando as mtricas para o conjunto de validao\n",
    "        val_acc = (y_true_val == y_pred_val).mean()\n",
    "        val_f1 = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "        val_precision = precision_score(y_true_val, y_pred_val, average='weighted')\n",
    "        val_recall = recall_score(y_true_val, y_pred_val, average='weighted')\n",
    "\n",
    "        # Armazenando as mtricas e a perda\n",
    "        self.train_accuracy.append(train_acc)\n",
    "        self.val_accuracy.append(val_acc)\n",
    "        self.train_f1.append(train_f1)\n",
    "        self.val_f1.append(val_f1)\n",
    "        self.train_precision.append(train_precision)\n",
    "        self.val_precision.append(val_precision)\n",
    "        self.train_recall.append(train_recall)\n",
    "        self.val_recall.append(val_recall)\n",
    "        self.train_loss.append(train_loss)\n",
    "        self.val_loss.append(val_loss)\n",
    "\n",
    "        # Exibindo as mtricas no final de cada poca\n",
    "        print(f\"Epoch {epoch + 1} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f}\")\n",
    "        print(f\"Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers (2885270193.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n"
     ]
    }
   ],
   "source": [
    "https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html\n",
    "https://www.kaggle.com/code/jvrco22/twitter-sentiment-analysis-96-val-acc#Models\n",
    "\n",
    "https://www.reddit.com/r/learnpython/comments/fayicq/vscode_the_term_conda_is_not_recognized_as_the/?rdt=49293\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
